install.packages("xquartz")
install.packages("xquartz")
install.packages("rgl")
allData <- read.csv ("https://raw.githubusercontent.com/rhsu4/542_Deliv1/main/allDataWide.csv")
row.names(allData) = NULL
#check data types
str(allData)
#Have to make LE2018 numeric
allData$LE2018<-as.numeric(allData$LE2018)
str(allData)
Sys.setenv(LIBGL_ALWAYS_SOFTWARE=1)
Sys.setenv(LIBGL_ALWAYS_SOFTWARE=1)
remove.packages("rgl")
install.packages("rgl")
allData <- read.csv ("https://raw.githubusercontent.com/rhsu4/542_Deliv1/main/allDataWide.csv")
row.names(allData) = NULL
#check data types
str(allData)
#Have to make LE2018 numeric
allData$LE2018<-as.numeric(allData$LE2018)
str(allData)
allData <- read.csv ("https://raw.githubusercontent.com/rhsu4/542_Deliv1/main/allDataWide.csv")
row.names(allData) = NULL
#check data types
str(allData)
#Have to make LE2018 numeric
allData$LE2018<-as.numeric(allData$LE2018)
str(allData)
#Setting row names as country names doesn't work because countries are repeating
selection=c("Country", "GiniPercent", "HE2018", "LE2018")
dataToCluster=allData[,selection]
#set labels as row index
row.names(dataToCluster) = dataToCluster$Country
dataToCluster$Country=NULL
#This will give you an error if the country is repeated (because row index names need to be unique)
#Decide if data needs to be transformed
boxplot(dataToCluster, horizontal=T)
#Yes, has to be transformed, on different scales
#### standardizing
DataToClusterStd<-as.data.frame(scale(dataToCluster))
### or smoothing
#log(DataToClusterStd)
boxplot(DataToClusterStd)
set.seed(999) # this is for replicability of results
dtcsFinal <- na.omit(DataToClusterStd)
#This includes only instances that have no missing values (153 obs left)
library(cluster)
dtcsFinal_DM = daisy (x=dtcsFinal, metric = "gower")
#This creates the distance metric
#for partitioning
library(factoextra)
#Missing values - have to either add imputed (mean) values, or remove variables that have missing data
#Here, removing NAs
fviz_nbclust(dtcsFinal,
pam,
diss=dtcsFinal_DM,
method = "gap_stat",
k.max = 10,verbose = F)
#Optimal number of clusters = 9
#hierarchical - agglomerative
fviz_nbclust(dtcsFinal,
hcut,
diss=dtcsFinal_DM,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "agnes")
#agglomerative optimal # of clusters = 4? 4 is a local average though, so maybe 8 or 9 is better
#hierarchical (divisive)
fviz_nbclust(dtcsFinal,
hcut,
diss=dtcsFinal_DM,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "diana")
#divisive clusters = 2 with local average. Actual ideal might be 7
NumberOfClusterDesired=4
#For clusters = 9, highest avg silhouette width = .33
#For clusters = 4, highest avg silhouette width = .37 (pam and agnes)
#For clusters = 2, highest avg silhouette width = .38 (pam and diana)
#For clusters = 7, highest avg silhouette width = .34 (agnes)
#For clusters = 8, highest avg silhouette width = .34 (diana)
#FLAG: Is 2 clusters enough clusters?
#Will go with 4, highest avg silhouette width while > 2 clusters
# Partitioning technique
res.pam = pam(x=dtcsFinal_DM,
k = NumberOfClusterDesired,
cluster.only = F)
# Hierarchical technique- agglomerative approach
#library(factoextra)
res.agnes= hcut(x=dtcsFinal_DM,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "ward.D2")
# Hierarchical technique- divisive approach
res.diana= hcut(x=dtcsFinal_DM,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='diana',
hc_method = "ward.D2")
#Is recoding supposed to put these in order?
library(dplyr)
#2.1 Add results to original data frame:
dtcsFinal$pam=as.factor(res.pam$clustering)
dtcsFinal$agn=as.factor(res.agnes$cluster)
dtcsFinal$dia=as.factor(res.diana$cluster)
#Verify ordinality in clusters
#aggregate(data=dtcsFinal,
#          Overallscore~pam, #how do we know what the dependent variable should be?
#          FUN=mean)
aggregate(data=dtcsFinal,
LE2018~pam,
FUN=mean)
#These are not ordinal data
aggregate(data=dtcsFinal,
LE2018~agn,
FUN=mean)
aggregate(data=dtcsFinal,
LE2018~dia,
FUN=mean)
dtcsFinal$pam=dplyr::recode_factor(dtcsFinal$pam,
`1` = '2',`2`='1',`3`='3',`4`='4')
dtcsFinal$agn=dplyr::recode_factor(dtcsFinal$agn,
`1` = '2',`2`='4',`3`='4',`4`='3')
dtcsFinal$dia=dplyr::recode_factor(dtcsFinal$dia,
`1` = '3',`2`='2',`3`='4',`4`='1')
fviz_silhouette(res.pam)
fviz_silhouette(res.agnes)
library(factoextra)
fviz_silhouette(res.diana)
head(data.frame(res.pam$silinfo$widths),10)
pamEval=data.frame(res.pam$silinfo$widths)
agnEval=data.frame(res.agnes$silinfo$widths)
diaEval=data.frame(res.diana$silinfo$widths)
pamPoor=rownames(pamEval[pamEval$sil_width<0,])
agnPoor=rownames(agnEval[agnEval$sil_width<0,])
diaPoor=rownames(diaEval[diaEval$sil_width<0,])
#install."qpcr"
library("qpcR")
#If I can ever get rgl to work - see which instances are badly clustered
bap_Clus=as.data.frame(qpcR:::cbind.na(sort(pamPoor), sort(agnPoor),sort(diaPoor)))
names(bap_Clus)=c("pam","agn","dia")
bap_Clus
projectedData = cmdscale(dtcsFinal_DM, k=2)
#
# save coordinates to original data frame:
dtcsFinal$dim1 = projectedData[,1]
dtcsFinal$dim2 = projectedData[,2]
# see some:
dtcsFinal[,c('dim1','dim2')][1:10,]
#base= ggplot(data=dtcsFinal,
#             aes(x=dim1, y=dim2,
#                 label=Country))
#base + geom_text(size=2)
base= ggplot(data=dtcsFinal,
aes(x=dim1, y=dim2,
label = rownames(dtcsFinal)))
base + geom_text(size=2)
pamPlot=base + labs(title = "PAM") + geom_point(size=2,
aes(color=pam),
show.legend = T)
agnPlot=base + labs(title = "AGNES") + geom_point(size=2,
aes(color=agn),
show.legend = T)
diaPlot=base + labs(title = "DIANA") + geom_point(size=2,
aes(color=dia),
show.legend = T)
library(ggpubr)
ggarrange(pamPlot, agnPlot, diaPlot,ncol = 3,common.legend = T)
# If name of country in black list, use it, else get rid of it
#LABELpam=ifelse(dtcsFinal$rowname%in%pamPoor,dtcsFinal$rowname,"")
#LABELdia=ifelse(dtcsFinal$Country%in%diaPoor,dtcsFinal$Country,"")
#LABELagn=ifelse(dtcsFinal$Country%in%agnPoor,dtcsFinal$Country,"")
#HOMEWORK NOTE: This isn't working because rgl package won't work
LABELpam=ifelse(rowname(dtcsFinal)%in%pamPoor,rowname(dtcsFinal),"")
# If name of country in black list, use it, else get rid of it
#LABELpam=ifelse(dtcsFinal$rowname%in%pamPoor,dtcsFinal$rowname,"")
#LABELdia=ifelse(dtcsFinal$Country%in%diaPoor,dtcsFinal$Country,"")
#LABELagn=ifelse(dtcsFinal$Country%in%agnPoor,dtcsFinal$Country,"")
#HOMEWORK NOTE: This isn't working because rgl package won't work
LABELpam=ifelse(row.name(dtcsFinal)%in%pamPoor,row.name(dtcsFinal),"")
# If name of country in black list, use it, else get rid of it
#LABELpam=ifelse(dtcsFinal$rowname%in%pamPoor,dtcsFinal$rowname,"")
#LABELdia=ifelse(dtcsFinal$Country%in%diaPoor,dtcsFinal$Country,"")
#LABELagn=ifelse(dtcsFinal$Country%in%agnPoor,dtcsFinal$Country,"")
#HOMEWORK NOTE: This isn't working because rgl package won't work
LABELpam=ifelse(row.names(dtcsFinal)%in%pamPoor,row.names(dtcsFinal),"")
LABELdia=ifelse(row.names(dtcsFinal)%in%diaPoor,row.names(dtcsFinal),"")
LABELagn=ifelse(row.names(dtcsFinal)%in%agnPoor,row.names(dtcsFinal),"")
library(ggrepel)
pamPlot + geom_text_repel(aes(label=LABELpam))
library(ggrepel)
pamPlot + geom_text_repel(aes(label=LABELpam), max.overlaps = Inf)
diaPlot + geom_text_repel(aes(label=LABELdia))
agnPlot + geom_text_repel(aes(label=LABELagn))
agnPlot + geom_text_repel(aes(label=LABELagn), max.overlaps = Inf)
fviz_dend(res.agnes,k=NumberOfClusterDesired, cex = 0.45, horiz = T,main = "AGNES approach")
fviz_dend(res.diana,k=NumberOfClusterDesired, cex = 0.45, horiz = T,main = "DIANA approach")
#Creating FA data
#selection
dataForFA = dtcsFinal
names(dataForFA)
library(lavaan)
model = 'healthsys=~ HE2018 + LE2018 + GiniPercent'
fit <- cfa(model, data = dataForFA, std.lv = TRUE)
indexCFA=lavPredict(fit)
indexCFA[1:10]
#Rescale to 0:10
library(scales)
indexCFANorm=rescale(as.vector(indexCFA),
to = c(0, 10))
indexCFANorm[1:10]
#This is our index
dataForFA$demo_FA=indexCFANorm
base=ggplot(data=dataForFA,
aes(x=demo_FA,y=LE2018))
base+geom_point()
evalCFA1=parameterEstimates(fit, standardized =TRUE)
evalCFA1[evalCFA1$op=="=~",c('rhs','std.all','pvalue')]
evalCFA2=as.list(fitMeasures(fit))
evalCFA2[c("chisq", "df", "pvalue")]
evalCFA2$tli # > 0.90
evalCFA2[c( 'rmsea.ci.lower','rmsea','rmsea.ci.upper')]
#install.packages("semPlot")
library(semPlot)
semPaths(fit, what='std', nCharNodes=0, sizeMan=12,
edge.label.cex=1.5, fade=T,residuals = F)
regData = dtcsFinal
`
regData = dtcsFinal
#FLAG -  Gini is negatively coded (higher gini = higher inequality)
# hypothesis 1: 2018LE increases as gini percent DECREASES (higher equality):
hypo1=formula(LE2018~ GiniPercent)
# hypothesis 2: 2018 LE increases as health expenditure of a country increases
hypo2=formula(LE2018~ HE2018)
#hypothesis 3: 2018 LE increases with higher health expenditure and lower gini score
# -  does this mean needing to make gini negative?
hypo3=formula(LE2018~ HE2018 + GiniPercent)
#
# results
gauss1=glm(hypo1,
data = regData,
family = 'gaussian')
gauss2=glm(hypo2,
data = regData,
family = 'gaussian')
gauss3=glm(hypo3,
data = regData,
family = 'gaussian')
summary(gauss1)
summary(gauss2)
summary(gauss3)
anova(gauss1, gauss2, test="Chisq")
anova(gauss1, gauss3, test="Chisq")
anova(gauss2, gauss3, test="Chisq")
#install.packages("rsq")
library(rsq)
rsq(gauss3, adj=T)
plot(gauss3,1)
plot(gauss3,2)
# The data is normal if the p-value is above 0.05
shapiro.test(gauss3$residuals)
plot(gauss2, 3)
#install.packages("lmtest")
library(lmtest)
#pvalue<0.05 you cannot assume Homoscedasticity
bptest(gauss3)
library(car)
vif(gauss3)
plot(gauss3,5)
gaussInf=as.data.frame(influence.measures(gauss3)$is.inf)
gaussInf[gaussInf$cook.d,]
#install.packages("sjPlot")
library(sjPlot)
plot_models(gauss3,vline.color="grey")
#install.packages("caret")
library(caret)
set.seed(123)
selection = createDataPartition(regData$LE2018,
p = 0.75,
list = FALSE)
#
trainGauss = regData[ selection, ]
#
testGauss  = regData[-selection, ]
ctrl = trainControl(method = 'cv',number = 5)
gauss3CV = train(hypo3,
data = trainGauss,
method = 'glm',
trControl = ctrl)
gauss3CV
predictedVal<-predict(gauss3CV,testGauss)
postResample(obs = testGauss$LE2018,
pred=predictedVal)
